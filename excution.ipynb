{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "wDf-gKwgHQc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvy8IiYi-WV-",
        "outputId": "703e1013-5dc7-4cd8-ea64-ce9e499552bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l8enVY2x-WV_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.dataset import Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import enum\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset"
      ],
      "metadata": {
        "id": "YvD5g-iyHXv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DfLerBb9-WWD"
      },
      "outputs": [],
      "source": [
        "class QuestionType(enum.Enum):\n",
        "    WHICH_ONE = 'which_one'\n",
        "    IS_IN = 'is_in'\n",
        "class DataSet(enum.Enum):\n",
        "    MNIST = 'mnist'\n",
        "    CIFAR10 = 'cifar10'\n",
        "    CIFAR100 = 'cifar100'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCtQIfkQ-WWD",
        "outputId": "313c94bf-126a-4386-fece-bbbdb481777a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def generate_cifar10_dataloader(batch_size: int) -> [DataLoader, DataLoader, DataLoader, DataLoader]:\n",
        "    train_transform = T.Compose(\n",
        "        [T.ToTensor(), # transforms.RandomHorizontalFlip(), transforms.RandomCrop(32,4),\n",
        "         T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "    test_transform = T.Compose(\n",
        "        [T.ToTensor(),\n",
        "         T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, transform=test_transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    full_train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=len(train_dataset.data), shuffle=False, num_workers=0)\n",
        "    return full_train_loader, train_loader, test_loader\n",
        "full_train_loader, train_loader, test_loader = generate_cifar10_dataloader(256)\n",
        "datas, labels = next(iter(full_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUKSD9Z8-WWE",
        "outputId": "20a09a6d-c819-4a04-ad66-7d90f0cd226b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def generate_Q_A_label(single_class_assigned: int, \n",
        "                         question_type: int, \n",
        "                         all_class_size: int, \n",
        "                         question_class_size: int) -> list:\n",
        "    \n",
        "    all_class_set = range(all_class_size)\n",
        "    question_class_set = random.sample(all_class_set, question_class_size)\n",
        "    temporary_label_list = [0 for i in range(all_class_size)]\n",
        "    \n",
        "    if question_type == QuestionType.WHICH_ONE:\n",
        "        if single_class_assigned in question_class_set:\n",
        "            for i in [single_class_assigned]:\n",
        "                temporary_label_list[i] = 1\n",
        "        \n",
        "        else:\n",
        "            comp_question_class_set = [i for i in all_class_set if i not in question_class_set]\n",
        "            for i in comp_question_class_set:\n",
        "                temporary_label_list[i] = 1\n",
        "        \n",
        "    elif question_type == QuestionType.IS_IN:\n",
        "        if single_class_assigned in question_class_set:\n",
        "            for i in question_class_set:\n",
        "                temporary_label_list[i] = 1\n",
        "        \n",
        "        else:\n",
        "            comp_question_class_set = [i for i in all_class_set if i not in question_class_set]\n",
        "            for i in comp_question_class_set:\n",
        "                temporary_label_list[i] = 1\n",
        "    \n",
        "    return temporary_label_list\n",
        "\n",
        "temporary_label_list = generate_Q_A_label(single_class_assigned=6, \n",
        "                                            question_type=QuestionType.WHICH_ONE, \n",
        "                                            all_class_size=10, \n",
        "                                            question_class_size=9)\n",
        "\n",
        "temporary_label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4ROvIYgF-WWF"
      },
      "outputs": [],
      "source": [
        "def generate_Q_A_labels(labels_tensor: torch.tensor, \n",
        "                          question_type: QuestionType,\n",
        "                          all_class_size: int,\n",
        "                          question_class_size: int) -> torch.tensor:\n",
        "    \n",
        "    labels_list = labels_tensor.tolist()\n",
        "    Q_A_labels_list = []\n",
        "    \n",
        "    for label in labels_list:\n",
        "        Q_A_label = generate_Q_A_label(single_class_assigned=label, \n",
        "                                          question_type=question_type,  # change out of this function\n",
        "                                          all_class_size=all_class_size, # change out of this function\n",
        "                                          question_class_size=question_class_size) # change out of this function\n",
        "        Q_A_labels_list.append(Q_A_label)\n",
        "        \n",
        "    Q_A_labels_tensor = torch.tensor(Q_A_labels_list)\n",
        "    \n",
        "    return Q_A_labels_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6FaB4-l-WWF",
        "outputId": "6c57d845-ed30-42a2-c8eb-88da971ed459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 1.2018e+00,  1.1700e+00,  1.1541e+00,  ...,  1.0906e+00,\n",
            "            1.0430e+00,  9.4773e-01],\n",
            "          [ 1.1541e+00,  1.1383e+00,  1.1224e+00,  ...,  1.1383e+00,\n",
            "            1.1065e+00,  1.0747e+00],\n",
            "          [ 1.1224e+00,  1.1065e+00,  1.1224e+00,  ...,  1.0271e+00,\n",
            "            1.0747e+00,  1.1383e+00],\n",
            "          ...,\n",
            "          [ 4.0792e-01,  2.6879e-02, -2.1127e-01,  ...,  6.3020e-01,\n",
            "            6.6195e-01,  7.5721e-01],\n",
            "          [ 3.9205e-01,  3.1266e-01,  2.0152e-01,  ...,  6.3020e-01,\n",
            "            7.5721e-01,  7.2546e-01],\n",
            "          [ 5.1906e-01,  5.1906e-01,  5.3494e-01,  ...,  6.1432e-01,\n",
            "            6.4607e-01,  7.0958e-01]],\n",
            "\n",
            "         [[ 1.1626e+00,  1.0980e+00,  1.0819e+00,  ...,  1.0496e+00,\n",
            "            1.0335e+00,  1.0173e+00],\n",
            "          [ 1.0980e+00,  1.0657e+00,  1.0335e+00,  ...,  1.1949e+00,\n",
            "            1.2594e+00,  1.3078e+00],\n",
            "          [ 1.0657e+00,  1.0012e+00,  1.0335e+00,  ...,  1.0819e+00,\n",
            "            1.1464e+00,  1.2433e+00],\n",
            "          ...,\n",
            "          [ 3.2339e-01, -3.1647e-02, -2.4144e-01,  ...,  4.6864e-01,\n",
            "            5.3319e-01,  6.9457e-01],\n",
            "          [ 2.4270e-01,  2.1043e-01,  1.7815e-01,  ...,  4.5250e-01,\n",
            "            5.4933e-01,  6.3002e-01],\n",
            "          [ 2.4270e-01,  3.2339e-01,  4.6864e-01,  ...,  4.3636e-01,\n",
            "            3.8794e-01,  5.4933e-01]],\n",
            "\n",
            "         [[ 1.8244e-01,  1.3737e-01,  1.3737e-01,  ...,  1.9747e-01,\n",
            "            2.5757e-01,  2.8762e-01],\n",
            "          [ 2.1249e-01,  1.9747e-01,  1.8244e-01,  ...,  2.2752e-01,\n",
            "            3.3269e-01,  4.0782e-01],\n",
            "          [ 2.1249e-01,  1.8244e-01,  1.9747e-01,  ...,  1.3737e-01,\n",
            "            2.5757e-01,  3.7777e-01],\n",
            "          ...,\n",
            "          [-2.0821e-01, -5.0871e-01, -6.5897e-01,  ..., -4.3359e-01,\n",
            "           -3.7349e-01, -2.2324e-01],\n",
            "          [-3.5846e-01, -3.8851e-01, -4.0354e-01,  ..., -3.7349e-01,\n",
            "           -2.9836e-01, -2.5329e-01],\n",
            "          [-2.9836e-01, -2.3826e-01, -1.4811e-01,  ..., -3.1339e-01,\n",
            "           -3.4344e-01, -2.6831e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.0179e-01, -4.4942e-01, -4.6530e-01,  ..., -4.0179e-01,\n",
            "           -4.9705e-01, -4.0179e-01],\n",
            "          [-4.1767e-01, -4.4942e-01, -4.4942e-01,  ..., -5.6056e-01,\n",
            "           -5.9232e-01, -4.8118e-01],\n",
            "          [-4.1767e-01, -4.3355e-01, -4.1767e-01,  ..., -5.1293e-01,\n",
            "           -5.2881e-01, -3.8592e-01],\n",
            "          ...,\n",
            "          [-4.8118e-01, -6.3995e-01, -5.6056e-01,  ..., -4.3355e-01,\n",
            "           -5.9232e-01, -6.5582e-01],\n",
            "          [-4.6530e-01, -4.4942e-01, -5.1293e-01,  ..., -4.3355e-01,\n",
            "           -6.3995e-01, -4.6530e-01],\n",
            "          [-6.3995e-01, -5.9232e-01, -8.1459e-01,  ..., -4.8118e-01,\n",
            "           -6.2407e-01, -4.0179e-01]],\n",
            "\n",
            "         [[-3.5441e-01, -4.0282e-01, -4.1896e-01,  ..., -3.8669e-01,\n",
            "           -4.8351e-01, -3.7055e-01],\n",
            "          [-3.7055e-01, -3.8669e-01, -3.8669e-01,  ..., -5.4807e-01,\n",
            "           -5.8034e-01, -4.0282e-01],\n",
            "          [-3.7055e-01, -3.7055e-01, -3.2213e-01,  ..., -4.9965e-01,\n",
            "           -5.1579e-01, -3.2213e-01],\n",
            "          ...,\n",
            "          [-4.6738e-01, -6.1262e-01, -5.1579e-01,  ..., -3.5441e-01,\n",
            "           -6.2876e-01, -7.2559e-01],\n",
            "          [-4.1896e-01, -4.0282e-01, -4.6738e-01,  ..., -3.2213e-01,\n",
            "           -6.4490e-01, -4.6738e-01],\n",
            "          [-5.9648e-01, -5.8034e-01, -8.0628e-01,  ..., -3.7055e-01,\n",
            "           -6.2876e-01, -3.2213e-01]],\n",
            "\n",
            "         [[-2.8334e-01, -3.2841e-01, -3.2841e-01,  ..., -3.1339e-01,\n",
            "           -3.8851e-01, -2.8334e-01],\n",
            "          [-2.9836e-01, -3.1339e-01, -3.2841e-01,  ..., -4.6364e-01,\n",
            "           -4.9369e-01, -2.9836e-01],\n",
            "          [-2.9836e-01, -2.9836e-01, -2.6831e-01,  ..., -4.1856e-01,\n",
            "           -4.3359e-01, -2.0821e-01],\n",
            "          ...,\n",
            "          [-3.7349e-01, -5.0871e-01, -4.0354e-01,  ..., -2.2324e-01,\n",
            "           -5.6882e-01, -6.7399e-01],\n",
            "          [-3.2841e-01, -3.1339e-01, -3.5846e-01,  ..., -1.4811e-01,\n",
            "           -5.9887e-01, -4.0354e-01],\n",
            "          [-4.9369e-01, -4.7866e-01, -7.1907e-01,  ..., -1.9319e-01,\n",
            "           -5.9887e-01, -1.9319e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.0653e-01, -1.3189e-01, -1.0013e-01,  ...,  1.1003e-02,\n",
            "           -5.2505e-02, -1.3189e-01],\n",
            "          [-5.9232e-01, -6.2407e-01, -6.5582e-01,  ..., -3.8592e-01,\n",
            "           -3.7004e-01, -4.0179e-01],\n",
            "          [-5.6056e-01, -5.9232e-01, -6.3995e-01,  ..., -2.7478e-01,\n",
            "           -3.0653e-01, -3.5416e-01],\n",
            "          ...,\n",
            "          [ 1.2018e+00,  1.3447e+00,  1.3447e+00,  ...,  7.4134e-01,\n",
            "            6.9370e-01,  6.4607e-01],\n",
            "          [ 2.9679e-01,  5.6669e-01,  1.1065e+00,  ...,  7.5721e-01,\n",
            "            6.6195e-01,  6.9370e-01],\n",
            "          [ 3.4442e-01,  8.3660e-01,  1.0747e+00,  ...,  3.6029e-01,\n",
            "            2.0152e-01,  1.5389e-01]],\n",
            "\n",
            "         [[-2.4144e-01, -4.7785e-02, -3.1647e-02,  ..., -1.5509e-02,\n",
            "           -8.0061e-02, -1.6075e-01],\n",
            "          [-5.3193e-01, -5.6421e-01, -5.9648e-01,  ..., -3.8669e-01,\n",
            "           -4.0282e-01, -4.3510e-01],\n",
            "          [-4.9965e-01, -5.3193e-01, -5.8034e-01,  ..., -2.4144e-01,\n",
            "           -3.3827e-01, -3.8669e-01],\n",
            "          ...,\n",
            "          [ 1.1303e+00,  1.2917e+00,  1.2755e+00,  ...,  6.6229e-01,\n",
            "            5.9774e-01,  5.4933e-01],\n",
            "          [ 2.4270e-01,  5.1705e-01,  1.0496e+00,  ...,  6.9457e-01,\n",
            "            5.8160e-01,  6.1388e-01],\n",
            "          [ 2.5884e-01,  7.5912e-01,  1.0173e+00,  ...,  2.9112e-01,\n",
            "            1.1360e-01,  6.5182e-02]],\n",
            "\n",
            "         [[-2.8334e-01, -1.1806e-01, -8.8010e-02,  ..., -1.2884e-02,\n",
            "           -7.2985e-02, -1.4811e-01],\n",
            "          [-5.5379e-01, -5.8384e-01, -6.1389e-01,  ..., -3.5846e-01,\n",
            "           -3.7349e-01, -4.0354e-01],\n",
            "          [-5.2374e-01, -5.5379e-01, -5.9887e-01,  ..., -2.3826e-01,\n",
            "           -3.1339e-01, -3.5846e-01],\n",
            "          ...,\n",
            "          [ 1.1290e+00,  1.2643e+00,  1.2492e+00,  ...,  6.0315e-01,\n",
            "            5.8812e-01,  5.4305e-01],\n",
            "          [ 1.8244e-01,  4.3787e-01,  9.3370e-01,  ...,  5.4305e-01,\n",
            "            4.8295e-01,  5.1300e-01],\n",
            "          [ 3.1767e-01,  7.8345e-01,  1.0239e+00,  ...,  1.9747e-01,\n",
            "            4.7217e-02,  2.1411e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.8118e-01, -6.2407e-01, -1.3189e-01,  ...,  5.1906e-01,\n",
            "            8.0484e-01,  7.7309e-01],\n",
            "          [-4.8118e-01, -8.3047e-01, -1.6364e-01,  ..., -5.2505e-02,\n",
            "            2.1740e-01,  2.8091e-01],\n",
            "          [-6.3995e-01, -8.3047e-01, -5.7644e-01,  ..., -2.1127e-01,\n",
            "            1.1003e-02,  4.2756e-02],\n",
            "          ...,\n",
            "          [ 5.8633e-02,  1.1003e-02, -3.0653e-01,  ..., -9.2573e-01,\n",
            "           -8.3047e-01, -1.0210e+00],\n",
            "          [ 1.6977e-01,  1.6977e-01,  2.6879e-02,  ..., -1.1321e+00,\n",
            "           -9.5748e-01, -1.1956e+00],\n",
            "          [ 2.3328e-01,  1.3802e-01,  2.3328e-01,  ..., -7.3521e-01,\n",
            "           -9.8924e-01, -1.2433e+00]],\n",
            "\n",
            "         [[-5.4807e-01, -8.7083e-01, -4.6738e-01,  ...,  1.6201e-01,\n",
            "            3.5567e-01,  3.5567e-01],\n",
            "          [-6.1262e-01, -1.0322e+00, -4.1896e-01,  ..., -5.1579e-01,\n",
            "           -3.5441e-01, -2.4144e-01],\n",
            "          [-8.0628e-01, -9.5152e-01, -8.0628e-01,  ..., -6.4490e-01,\n",
            "           -5.9648e-01, -5.6421e-01],\n",
            "          ...,\n",
            "          [-9.5152e-01, -9.8380e-01, -1.1613e+00,  ..., -1.2259e+00,\n",
            "           -1.1936e+00, -1.3711e+00],\n",
            "          [-6.2876e-01, -7.5786e-01, -9.8380e-01,  ..., -1.3227e+00,\n",
            "           -1.1613e+00, -1.3873e+00],\n",
            "          [ 6.2941e-04, -4.0282e-01, -6.6103e-01,  ..., -8.8697e-01,\n",
            "           -1.1129e+00, -1.3550e+00]],\n",
            "\n",
            "         [[-7.9419e-01, -9.7449e-01, -8.0922e-01,  ..., -1.3309e-01,\n",
            "           -2.7909e-02,  3.2191e-02],\n",
            "          [-6.8902e-01, -1.0045e+00, -8.2424e-01,  ..., -8.3927e-01,\n",
            "           -7.4912e-01, -5.6882e-01],\n",
            "          [-8.8434e-01, -1.0196e+00, -1.0496e+00,  ..., -8.5429e-01,\n",
            "           -8.6932e-01, -8.0922e-01],\n",
            "          ...,\n",
            "          [-1.1247e+00, -1.0646e+00, -1.3501e+00,  ..., -1.2299e+00,\n",
            "           -1.2299e+00, -1.3351e+00],\n",
            "          [-1.1698e+00, -1.2149e+00, -1.2750e+00,  ..., -1.3201e+00,\n",
            "           -1.1999e+00, -1.3351e+00],\n",
            "          [-6.4394e-01, -1.0196e+00, -1.0045e+00,  ..., -9.7449e-01,\n",
            "           -1.1398e+00, -1.3050e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6503e-01,  2.6503e-01,  2.9679e-01,  ..., -1.3862e+00,\n",
            "           -1.5132e+00, -9.4161e-01],\n",
            "          [ 3.1266e-01,  3.1266e-01,  3.4442e-01,  ..., -4.6530e-01,\n",
            "           -1.4179e+00, -1.5132e+00],\n",
            "          [ 3.6029e-01,  3.6029e-01,  3.9205e-01,  ...,  8.5247e-01,\n",
            "           -2.9066e-01, -1.2909e+00],\n",
            "          ...,\n",
            "          [ 8.2072e-01,  8.5247e-01,  9.0010e-01,  ...,  1.1383e+00,\n",
            "            1.1541e+00,  1.1224e+00],\n",
            "          [ 9.0010e-01,  9.0010e-01,  9.1598e-01,  ...,  1.0906e+00,\n",
            "            1.1065e+00,  1.1383e+00],\n",
            "          [ 8.6835e-01,  8.8423e-01,  9.4773e-01,  ...,  1.0747e+00,\n",
            "            1.1541e+00,  1.2176e+00]],\n",
            "\n",
            "         [[ 7.2685e-01,  7.2685e-01,  7.5912e-01,  ..., -1.3227e+00,\n",
            "           -1.4679e+00, -8.8697e-01],\n",
            "          [ 7.5912e-01,  7.5912e-01,  7.9140e-01,  ..., -2.7372e-01,\n",
            "           -1.3388e+00, -1.5002e+00],\n",
            "          [ 7.9140e-01,  7.9140e-01,  8.0754e-01,  ...,  1.1464e+00,\n",
            "           -1.4461e-01, -1.2420e+00],\n",
            "          ...,\n",
            "          [ 4.3636e-01,  4.8477e-01,  5.3319e-01,  ...,  5.9774e-01,\n",
            "            6.3002e-01,  5.9774e-01],\n",
            "          [ 5.4933e-01,  5.4933e-01,  5.8160e-01,  ...,  5.6546e-01,\n",
            "            5.8160e-01,  6.1388e-01],\n",
            "          [ 5.9774e-01,  5.9774e-01,  6.4616e-01,  ...,  5.8160e-01,\n",
            "            6.6229e-01,  7.2685e-01]],\n",
            "\n",
            "         [[ 1.2793e+00,  1.2793e+00,  1.3093e+00,  ..., -1.1548e+00,\n",
            "           -1.3351e+00, -7.6414e-01],\n",
            "          [ 1.2943e+00,  1.2943e+00,  1.3244e+00,  ..., -4.2934e-02,\n",
            "           -1.1548e+00, -1.3651e+00],\n",
            "          [ 1.3244e+00,  1.3093e+00,  1.3394e+00,  ...,  1.3845e+00,\n",
            "            7.7267e-02, -1.0797e+00],\n",
            "          ...,\n",
            "          [-2.8334e-01, -2.6831e-01, -2.5329e-01,  ..., -2.0821e-01,\n",
            "           -1.7816e-01, -2.0821e-01],\n",
            "          [-1.9319e-01, -2.0821e-01, -2.0821e-01,  ..., -2.3826e-01,\n",
            "           -2.2324e-01, -1.9319e-01],\n",
            "          [-1.3309e-01, -1.9319e-01, -1.7816e-01,  ..., -2.3826e-01,\n",
            "           -1.7816e-01, -1.0304e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.5108e-01, -7.5108e-01, -7.6696e-01,  ..., -7.1933e-01,\n",
            "           -7.1933e-01, -7.0345e-01],\n",
            "          [-6.7170e-01, -6.7170e-01, -6.8758e-01,  ..., -6.2407e-01,\n",
            "           -6.2407e-01, -5.4469e-01],\n",
            "          [-6.0819e-01, -6.0819e-01, -5.9232e-01,  ..., -5.7644e-01,\n",
            "           -5.6056e-01, -4.9705e-01],\n",
            "          ...,\n",
            "          [-1.3544e+00, -1.3862e+00, -1.4655e+00,  ..., -1.3862e+00,\n",
            "           -1.3862e+00, -1.3703e+00],\n",
            "          [-1.3703e+00, -1.3862e+00, -1.4655e+00,  ..., -1.3862e+00,\n",
            "           -1.3703e+00, -1.3703e+00],\n",
            "          [-1.4338e+00, -1.4497e+00, -1.4655e+00,  ..., -1.4497e+00,\n",
            "           -1.4655e+00, -1.4655e+00]],\n",
            "\n",
            "         [[ 1.0980e+00,  1.0980e+00,  1.0980e+00,  ...,  1.1303e+00,\n",
            "            1.1142e+00,  1.1303e+00],\n",
            "          [ 1.1464e+00,  1.1464e+00,  1.1303e+00,  ...,  1.1949e+00,\n",
            "            1.2110e+00,  1.2110e+00],\n",
            "          [ 1.1303e+00,  1.1464e+00,  1.1626e+00,  ...,  1.1949e+00,\n",
            "            1.2110e+00,  1.2110e+00],\n",
            "          ...,\n",
            "          [-1.0645e+00, -1.0645e+00, -1.0968e+00,  ..., -8.3855e-01,\n",
            "           -8.3855e-01, -8.2242e-01],\n",
            "          [-9.8380e-01, -9.5152e-01, -9.6766e-01,  ..., -8.5469e-01,\n",
            "           -8.8697e-01, -8.8697e-01],\n",
            "          [-9.3538e-01, -8.8697e-01, -8.7083e-01,  ..., -8.8697e-01,\n",
            "           -8.8697e-01, -8.8697e-01]],\n",
            "\n",
            "         [[ 1.7601e+00,  1.7601e+00,  1.7451e+00,  ...,  1.8502e+00,\n",
            "            1.8352e+00,  1.8202e+00],\n",
            "          [ 1.7751e+00,  1.7901e+00,  1.7751e+00,  ...,  1.8502e+00,\n",
            "            1.8653e+00,  1.8502e+00],\n",
            "          [ 1.7601e+00,  1.7751e+00,  1.7751e+00,  ...,  1.8052e+00,\n",
            "            1.8352e+00,  1.8352e+00],\n",
            "          ...,\n",
            "          [-2.0821e-01, -1.7816e-01, -1.7816e-01,  ...,  4.7217e-02,\n",
            "            4.7217e-02,  6.2242e-02],\n",
            "          [-1.6314e-01, -1.4811e-01, -1.7816e-01,  ...,  3.2191e-02,\n",
            "           -1.2884e-02, -1.2884e-02],\n",
            "          [-1.0304e-01, -7.2985e-02, -4.2934e-02,  ...,  3.2191e-02,\n",
            "            1.7166e-02,  1.7166e-02]]]])\n",
            "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
            "3072\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "def generate_cifar10_dataloader_with_Q_A_label(full_train_loader: DataLoader, \n",
        "                                                  question_type: QuestionType,\n",
        "                                                  question_size: int,\n",
        "                                                  batch_size: int) ->[DataLoader, int, int]:\n",
        "    \n",
        "    for i, (datas, labels) in enumerate(full_train_loader):\n",
        "        all_class_size = torch.max(labels) + 1 # K is number of classes, full_train_loader is full batch\n",
        "        \n",
        "    Q_A_labels_tensor = generate_Q_A_labels(labels, question_type, all_class_size, question_size)\n",
        "    Q_A_labels_matrix_dataset = torch.utils.data.TensorDataset(datas, Q_A_labels_tensor.float())\n",
        "    Q_A_labels_matrix_train_loader = torch.utils.data.DataLoader(dataset=Q_A_labels_matrix_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    dimension = int(datas.reshape(-1).shape[0]/datas.shape[0])\n",
        "    return Q_A_labels_matrix_train_loader, dimension, all_class_size.tolist()\n",
        "\n",
        "Q_A_labels_matrix_train_loader, dimension, all_class_size = generate_cifar10_dataloader_with_Q_A_label(full_train_loader, \n",
        "                                                                                                           QuestionType.WHICH_ONE,\n",
        "                                                                                                           question_size=9,\n",
        "                                                                                                           batch_size=256)\n",
        "Q_A_datas, Q_A_labels = next(iter(Q_A_labels_matrix_train_loader))\n",
        "print(Q_A_datas)\n",
        "print(Q_A_labels)\n",
        "print(dimension)\n",
        "print(all_class_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQyJl_0N-WWG",
        "outputId": "df832967-0186-4a49-86a6-ae282f2195fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f2a5a0b2fd0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f29daec9b20>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f29d991e9d0>,\n",
              " 3072,\n",
              " 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from traitlets.traitlets import Integer\n",
        "# Unclear!!!\n",
        "DataSet_2_DataLoader_generator = {\n",
        "    #DataSet.MNIST: generate_mnist_dataloader,\n",
        "    DataSet.CIFAR10: generate_cifar10_dataloader,\n",
        "    #DataSet.CIFAR100: generate_cifar100_dataloader,\n",
        "}\n",
        "DataSet_2_DataLoader_generator_with_Q_A_label = {\n",
        "    #DataSet.MNIST: generate_mnist_dataloader,\n",
        "    DataSet.CIFAR10: generate_cifar10_dataloader_with_Q_A_label,\n",
        "    #DataSet.CIFAR100: generate_cifar100_dataloader,\n",
        "}\n",
        "\n",
        "def DataSet_2_DataLoader_with_Q_A_label(dataset: DataSet,\n",
        "                                             question_type: QuestionType,\n",
        "                                             question_size: int,\n",
        "                                             batch_size: int\n",
        "                                             ) -> [DataLoader, DataLoader, DataLoader, int, Integer]:\n",
        "    \n",
        "    dataloader_generator = DataSet_2_DataLoader_generator[dataset]\n",
        "    full_train_loader, train_loader, test_loader = dataloader_generator(batch_size)\n",
        "    dataloader_generator_with_Q_A_label = DataSet_2_DataLoader_generator_with_Q_A_label[dataset]\n",
        "    Q_A_labels_matrix_train_loader, dimension, all_class_size = dataloader_generator_with_Q_A_label(full_train_loader, question_type, question_size, batch_size)\n",
        "    \n",
        "    return Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size\n",
        "\n",
        "DataSet_2_DataLoader_with_Q_A_label(DataSet.CIFAR10, QuestionType.WHICH_ONE, 9, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model excution"
      ],
      "metadata": {
        "id": "_uttS2WgHgpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "izJeh7tu-WWG"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def mae_loss(outputs, labels):\n",
        "    sm_outputs = F.softmax(outputs, dim=1)\n",
        "    loss_fn = nn.L1Loss(reduction='none')\n",
        "    loss_matrix = loss_fn(sm_outputs, labels.float())\n",
        "    sample_loss = loss_matrix.sum(dim=-1)\n",
        "    return sample_loss\n",
        "    \n",
        "def mse_loss(outputs, labels):\n",
        "    sm_outputs = F.softmax(outputs, dim=1)\n",
        "    loss_fn = nn.MSELoss(reduction='none')\n",
        "    loss_matrix = loss_fn(sm_outputs, labels.float())\n",
        "    sample_loss = loss_matrix.sum(dim=-1)\n",
        "    return sample_loss\n",
        "\n",
        "def gce_loss(outputs, labels):\n",
        "    q = 0.7\n",
        "    sm_outputs = F.softmax(outputs, dim=1)\n",
        "    pow_outputs = torch.pow(sm_outputs, q)\n",
        "    sample_loss = (1-(pow_outputs*labels).sum(dim=1))/q # n\n",
        "    return sample_loss\n",
        "\n",
        "def phuber_ce_loss(outputs, labels):\n",
        "    trunc_point = 0.1\n",
        "    n = labels.shape[0]\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "    sm_outputs = soft_max(outputs)\n",
        "    final_outputs = sm_outputs * labels\n",
        "    final_confidence = final_outputs.sum(dim=1)\n",
        "   \n",
        "    ce_index = (final_confidence > trunc_point)\n",
        "    sample_loss = torch.zeros(n).to(device)\n",
        "\n",
        "    if ce_index.sum() > 0:\n",
        "        ce_outputs = outputs[ce_index,:]\n",
        "        logsm = nn.LogSoftmax(dim=-1)\n",
        "        logsm_outputs = logsm(ce_outputs)\n",
        "        final_ce_outputs = logsm_outputs * labels[ce_index,:]\n",
        "        sample_loss[ce_index] = - final_ce_outputs.sum(dim=-1)\n",
        "\n",
        "    linear_index = (final_confidence <= trunc_point)\n",
        "\n",
        "    if linear_index.sum() > 0:\n",
        "        sample_loss[linear_index] = -math.log(trunc_point) + (-1/trunc_point)*final_confidence[linear_index] + 1\n",
        "\n",
        "    return sample_loss\n",
        "\n",
        "def ce_loss(outputs, labels):\n",
        "    logsm = nn.LogSoftmax(dim=1)\n",
        "    logsm_outputs = logsm(outputs)\n",
        "    final_outputs = logsm_outputs * labels\n",
        "    sample_loss = - final_outputs.sum(dim=1)\n",
        "    return sample_loss\n",
        "\n",
        "def W_O_loss(loss_fn, outputs, labels, device, question_class_size, all_class_size):\n",
        "    n, k = labels.shape[0], labels.shape[1]\n",
        "    temp_loss = torch.zeros(n, k).to(device)\n",
        "    for i in range(k):\n",
        "        tempY = torch.zeros(n, k).to(device)\n",
        "        tempY[:, i] = 1.0\n",
        "        temp_loss[:, i] = loss_fn(outputs, tempY)\n",
        "        \n",
        "    candidate_loss = (temp_loss * labels).sum(dim=1)\n",
        "    noncandidate_loss = (temp_loss * (1-labels)).sum(dim=1)\n",
        "    total_loss = candidate_loss - ((all_class_size - question_class_size) * (all_class_size - question_class_size - 1))/(question_class_size * (2*all_class_size - question_class_size - 1.0)) * noncandidate_loss\n",
        "    average_loss = total_loss.mean()\n",
        "    return average_loss\n",
        "\n",
        "def I_I_loss(loss_fn, outputs, labels, device, question_class_size, all_class_size):\n",
        "    n, k = labels.shape[0], labels.shape[1]\n",
        "    temp_loss = torch.zeros(n, k).to(device)\n",
        "    for i in range(k):\n",
        "        tempY = torch.zeros(n, k).to(device)\n",
        "        tempY[:, i] = 1.0\n",
        "        temp_loss[:, i] = ce_loss(outputs, tempY)\n",
        "        \n",
        "    candidate_loss = (temp_loss * labels).sum(dim=1)\n",
        "    noncandidate_loss = (temp_loss * (1-labels)).sum(dim=1)\n",
        "    total_loss = candidate_loss - (2*question_class_size**2 + all_class_size**2 - all_class_size*(2*question_class_size + 1))/(2*question_class_size * (all_class_size - question_class_size)) * noncandidate_loss\n",
        "    average_loss = total_loss.mean()\n",
        "    return average_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7eQ0uYqy-WWH"
      },
      "outputs": [],
      "source": [
        "class mlp_model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(mlp_model, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(-1, self.num_flat_features(x))\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HiI0NlQ1-WWH"
      },
      "outputs": [],
      "source": [
        "def accuracy_check(loader, model, device):\n",
        "    with torch.no_grad():\n",
        "        total, num_samples = 0, 0\n",
        "        for images, labels in loader:\n",
        "            labels, images = labels.to(device), images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += (predicted == labels).sum().item()\n",
        "            num_samples += labels.size(0) \n",
        "    return total / num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "naI292b5-WWH"
      },
      "outputs": [],
      "source": [
        "def show_score(epoch,max_epoch, itr, max_itr, loss, acc, is_val=False):\n",
        "  if is_val:\n",
        "    print('\\r{} EPOCH[{:03}/{:03}] ITR [{:04}/{:04}] ACC:{:03f}'.format(\"TEST  \" if is_val else \"TRAIN\", epoch, max_epoch, itr, max_itr, acc*100),end = '')\n",
        "  \n",
        "  else:\n",
        "    print('\\r{} EPOCH[{:03}/{:03}] ITR [{:04}/{:04}] LOSS:{:.05f} ACC:{:03f}'.format(\"VAL  \" if is_val else \"TRAIN\", epoch, max_epoch, itr, max_itr, loss, acc*100), end = '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Qr7jT0aV-WWI"
      },
      "outputs": [],
      "source": [
        "def Train_Eval(model, \n",
        "               question_type, \n",
        "               question_class_size, \n",
        "               all_class_size, \n",
        "               criterion, \n",
        "               optimizer, \n",
        "               data_loader, \n",
        "               evaluation_data_loader_train, \n",
        "               evaluation_data_loader_test, \n",
        "               device, \n",
        "               epoch, \n",
        "               max_epoch):\n",
        "        \n",
        "    total_loss_train = 0.0\n",
        "    total_acc_train = 0.0\n",
        "    total_acc_test = 0.0\n",
        "    counter = 0\n",
        "\n",
        "    for n, (data, label) in enumerate(data_loader):\n",
        "        model.train()\n",
        "        counter += data.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(data)\n",
        "        if question_type == QuestionType.WHICH_ONE:\n",
        "            loss = W_O_loss(criterion, output, label.float(), device, question_class_size, all_class_size)\n",
        "        elif question_type == QuestionType.IS_IN:\n",
        "            loss = I_I_loss(criterion, output, label.float(), device, question_class_size, all_class_size)\n",
        "        else:\n",
        "            loss = criterion(output,label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss_train += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        total_acc_train += accuracy_check(evaluation_data_loader_train, model, device)\n",
        "        total_acc_test += accuracy_check(evaluation_data_loader_test, model, device)\n",
        "\n",
        "\n",
        "        show_score(epoch+1, max_epoch, n+1, len(data_loader), total_loss_train/(n+1), total_acc_train/counter, is_val=False)\n",
        "        print()\n",
        "        show_score(epoch+1, max_epoch, n+1, len(data_loader), '', total_acc_test/counter, is_val=True)\n",
        "        print()\n",
        "\n",
        "    return total_loss , total_acc_train, total_acc_test \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "U3UMkIUz-WWI"
      },
      "outputs": [],
      "source": [
        "def Q_A_label_Train_Eval(dataset, \n",
        "                          question_type, \n",
        "                          question_class_size, \n",
        "                          model, \n",
        "                          batch_size, \n",
        "                          loss_fn, \n",
        "                          EPOCHS):\n",
        "    Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size = DataSet_2_DataLoader_with_Q_A_label(dataset, \n",
        "                                                                                                                           question_type, \n",
        "                                                                                                                           question_class_size,\n",
        "                                                                                                                           batch_size)\n",
        "    DEVICE= torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model = model(input_dim=dimension, hidden_dim=500, output_dim=all_class_size).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "    \n",
        "    train_loss_list = []\n",
        "\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "    #criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss, train_acc, test_acc = Train_Eval(model=model, \n",
        "                                                    question_type=question_type,\n",
        "                                                    question_class_size=question_class_size,\n",
        "                                                    all_class_size=all_class_size,\n",
        "                                                    criterion=loss_fn,\n",
        "                                                    optimizer=optimizer, \n",
        "                                                    data_loader=Q_A_labels_matrix_train_loader,\n",
        "                                                    evaluation_data_loader_train=train_loader,\n",
        "                                                    evaluation_data_loader_test=test_loader,\n",
        "                                                    device=DEVICE, \n",
        "                                                    epoch=epoch, \n",
        "                                                    max_epoch=EPOCHS)\n",
        "\n",
        "        train_loss_list.append(train_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(f'TRAIN EPOCH[{epoch+1}/{EPOCHS}] LOSS: {train_loss_list.mean()} ACC:{train_acc_list.mean()}')\n",
        "        print(f'TEST EPOCH[{epoch+1}/{EPOCHS}] ACC:{test_acc_list.mean()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "i5I4hQib-WWI",
        "outputId": "6dc1435a-248a-4f8e-92bc-121f7695d939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "TRAIN EPOCH[001/300] ITR [0001/0782] LOSS:2.26217 ACC:0.310250\n",
            "TEST   EPOCH[001/300] ITR [0001/0782] ACC:0.312969\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-de0216018d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ_A_label_Train_Eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuestionType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHICH_ONE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-9780f9d839a8>\u001b[0m in \u001b[0;36mQ_A_label_Train_Eval\u001b[0;34m(dataset, question_type, question_class_size, model, batch_size, loss_fn, EPOCHS)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         train_loss, train_acc, test_acc = Train_Eval(model=model, \n\u001b[0m\u001b[1;32m     18\u001b[0m                                                     \u001b[0mquestion_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                     \u001b[0mquestion_class_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_class_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-25a07b67c41c>\u001b[0m in \u001b[0;36mTrain_Eval\u001b[0;34m(model, question_type, question_class_size, all_class_size, criterion, optimizer, data_loader, evaluation_data_loader_1, evaluation_data_loader_2, device, epoch, max_epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtotal_acc_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-fdf7d9ef1b66>\u001b[0m in \u001b[0;36maccuracy_check\u001b[0;34m(loader, model, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Q_A_label_Train_Eval(dataset=DataSet.CIFAR10, \n",
        "                      question_type=QuestionType.WHICH_ONE, \n",
        "                      question_class_size=9, \n",
        "                      model=mlp_model, \n",
        "                      batch_size=64, \n",
        "                      loss_fn=ce_loss, \n",
        "                      EPOCHS=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "klKwXNTl-WWI"
      },
      "outputs": [],
      "source": [
        "def Ord_label_Train_Eval(dataset, \n",
        "                          model, \n",
        "                          batch_size, \n",
        "                          loss_fn, \n",
        "                          EPOCHS):\n",
        "    Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size = DataSet_2_DataLoader_with_Q_A_label(dataset, \n",
        "                                                                                                                                   QuestionType.WHICH_ONE, \n",
        "                                                                                                                                   5,\n",
        "                                                                                                                                   batch_size)\n",
        "    DEVICE= torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model = model(input_dim=dimension, hidden_dim=500, output_dim=all_class_size).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "    \n",
        "    train_loss_list = []\n",
        "\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "    #criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss,train_acc = Train_Eval(model=model, \n",
        "                                          question_type=None,\n",
        "                                          question_class_size=None,\n",
        "                                          all_class_size=None,\n",
        "                                          criterion=loss_fn,\n",
        "                                          optimizer=optimizer, \n",
        "                                          data_loader=train_loader,\n",
        "                                          evaluation_data_loader_train=train_loader,\n",
        "                                          evaluation_data_loader_test=test_loader,\n",
        "                                          device=DEVICE, \n",
        "                                          epoch=epoch, \n",
        "                                          max_epoch=EPOCHS)\n",
        "        \n",
        "\n",
        "        train_loss_list.append(train_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(f'TRAIN EPOCH[{epoch+1}/{EPOCHS}] LOSS: {train_loss_list.mean()} ACC:{train_acc_list.mean()}')\n",
        "        print(f'TEST EPOCH[{epoch+1}/{EPOCHS}] ACC:{test_acc_list.mean()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "6WUN_qgA-WWJ",
        "outputId": "25085349-1b02-4194-fc5c-db96a3e74c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "TRAIN EPOCH[001/300] ITR [0001/0782] LOSS:2.32732 ACC:0.312250\n",
            "TEST   EPOCH[001/300] ITR [0001/0782] ACC:0.317812\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-63509f12d064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Ord_label_Train_Eval(dataset=DataSet.CIFAR10, \n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       EPOCHS=300)\n",
            "\u001b[0;32m<ipython-input-56-87ee05022a96>\u001b[0m in \u001b[0;36mOrd_label_Train_Eval\u001b[0;34m(dataset, model, batch_size, loss_fn, EPOCHS)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         train_loss,train_acc = Train_Eval(model=model, \n\u001b[0m\u001b[1;32m     22\u001b[0m                                           \u001b[0mquestion_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                           \u001b[0mquestion_class_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-852f6455ca01>\u001b[0m in \u001b[0;36mTrain_Eval\u001b[0;34m(model, question_type, question_class_size, all_class_size, criterion, optimizer, data_loader, evaluation_data_loader_train, evaluation_data_loader_test, device, epoch, max_epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtotal_acc_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-fdf7d9ef1b66>\u001b[0m in \u001b[0;36maccuracy_check\u001b[0;34m(loader, model, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \"\"\"\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Ord_label_Train_Eval(dataset=DataSet.CIFAR10, \n",
        "                      model=mlp_model, \n",
        "                      batch_size=64, \n",
        "                      loss_fn=nn.CrossEntropyLoss(), \n",
        "                      EPOCHS=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k02cVpT4-WWJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "instance_type": "ml.g4dn.xlarge",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}