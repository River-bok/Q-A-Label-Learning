{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDf-gKwgHQc6"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kvy8IiYi-WV-",
    "outputId": "703e1013-5dc7-4cd8-ea64-ce9e499552bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.6.0+cu101)\n",
      "Requirement already satisfied: future in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (1.20.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.7.0+cu101)\n",
      "Requirement already satisfied: numpy in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: torch==1.6.0 in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision) (1.6.0+cu101)\n",
      "Requirement already satisfied: future in c:\\users\\karub\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch==1.6.0->torchvision) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l8enVY2x-WV_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.dataset import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import enum\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvD5g-iyHXv0"
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DfLerBb9-WWD"
   },
   "outputs": [],
   "source": [
    "class QuestionType(enum.Enum):\n",
    "    WHICH_ONE = 'which_one'\n",
    "    IS_IN = 'is_in'\n",
    "class DataSet(enum.Enum):\n",
    "    MNIST = 'mnist'\n",
    "    CIFAR10 = 'cifar10'\n",
    "    CIFAR100 = 'cifar100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCtQIfkQ-WWD",
    "outputId": "313c94bf-126a-4386-fece-bbbdb481777a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def generate_cifar10_dataloader(batch_size: int) -> [DataLoader, DataLoader, DataLoader, DataLoader]:\n",
    "    train_transform = T.Compose(\n",
    "        [T.ToTensor(), # transforms.RandomHorizontalFlip(), transforms.RandomCrop(32,4),\n",
    "         T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "    test_transform = T.Compose(\n",
    "        [T.ToTensor(),\n",
    "         T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, transform=test_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    full_train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=len(train_dataset.data), shuffle=False, num_workers=0)\n",
    "    return full_train_loader, train_loader, test_loader\n",
    "full_train_loader, train_loader, test_loader = generate_cifar10_dataloader(256)\n",
    "datas, labels = next(iter(full_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUKSD9Z8-WWE",
    "outputId": "20a09a6d-c819-4a04-ad66-7d90f0cd226b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_Q_A_label(single_class_assigned: int, \n",
    "                         question_type: int, \n",
    "                         all_class_size: int, \n",
    "                         question_class_size: int) -> list:\n",
    "    \n",
    "    all_class_set = range(all_class_size)\n",
    "    question_class_set = random.sample(all_class_set, question_class_size)\n",
    "    temporary_label_list = [0 for i in range(all_class_size)]\n",
    "    \n",
    "    if question_type == QuestionType.WHICH_ONE:\n",
    "        if single_class_assigned in question_class_set:\n",
    "            for i in [single_class_assigned]:\n",
    "                temporary_label_list[i] = 1\n",
    "        \n",
    "        else:\n",
    "            comp_question_class_set = [i for i in all_class_set if i not in question_class_set]\n",
    "            for i in comp_question_class_set:\n",
    "                temporary_label_list[i] = 1\n",
    "        \n",
    "    elif question_type == QuestionType.IS_IN:\n",
    "        if single_class_assigned in question_class_set:\n",
    "            for i in question_class_set:\n",
    "                temporary_label_list[i] = 1\n",
    "        \n",
    "        else:\n",
    "            comp_question_class_set = [i for i in all_class_set if i not in question_class_set]\n",
    "            for i in comp_question_class_set:\n",
    "                temporary_label_list[i] = 1\n",
    "    \n",
    "    return temporary_label_list\n",
    "\n",
    "temporary_label_list = generate_Q_A_label(single_class_assigned=6, \n",
    "                                            question_type=QuestionType.WHICH_ONE, \n",
    "                                            all_class_size=10, \n",
    "                                            question_class_size=9)\n",
    "\n",
    "temporary_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4ROvIYgF-WWF"
   },
   "outputs": [],
   "source": [
    "def generate_Q_A_labels(labels_tensor: torch.tensor, \n",
    "                          question_type: QuestionType,\n",
    "                          all_class_size: int,\n",
    "                          question_class_size: int) -> torch.tensor:\n",
    "    \n",
    "    labels_list = labels_tensor.tolist()\n",
    "    Q_A_labels_list = []\n",
    "    \n",
    "    for label in labels_list:\n",
    "        Q_A_label = generate_Q_A_label(single_class_assigned=label, \n",
    "                                          question_type=question_type,  # change out of this function\n",
    "                                          all_class_size=all_class_size, # change out of this function\n",
    "                                          question_class_size=question_class_size) # change out of this function\n",
    "        Q_A_labels_list.append(Q_A_label)\n",
    "        \n",
    "    Q_A_labels_tensor = torch.tensor(Q_A_labels_list)\n",
    "    \n",
    "    return Q_A_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6FaB4-l-WWF",
    "outputId": "6c57d845-ed30-42a2-c8eb-88da971ed459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1700,  1.0112,  1.0430,  ...,  1.0589,  1.0747,  1.0747],\n",
      "          [ 0.9160,  0.7731,  0.8048,  ...,  0.7096,  0.7255,  0.7890],\n",
      "          [ 1.0112,  0.8525,  0.9160,  ...,  0.7890,  0.8207,  0.8683],\n",
      "          ...,\n",
      "          [ 1.3764,  1.2176,  1.3129,  ...,  1.2970,  1.3447,  1.3129],\n",
      "          [ 1.3447,  1.1700,  1.1383,  ...,  1.1224,  1.3129,  1.2176],\n",
      "          [ 1.4240,  1.2970,  1.1700,  ...,  1.2018,  1.3129,  1.2970]],\n",
      "\n",
      "         [[ 1.3724,  1.2755,  1.2917,  ...,  1.2755,  1.2594,  1.2917],\n",
      "          [ 1.3562,  1.2433,  1.2433,  ...,  1.2917,  1.2755,  1.2755],\n",
      "          [ 1.3724,  1.2594,  1.2755,  ...,  1.3240,  1.3240,  1.3240],\n",
      "          ...,\n",
      "          [ 1.2271,  1.1626,  1.1949,  ...,  1.2433,  1.2271,  1.2917],\n",
      "          [ 1.2110,  1.1142,  1.0335,  ...,  1.0657,  1.1787,  1.1949],\n",
      "          [ 1.1949,  1.1464,  0.9851,  ...,  1.0657,  1.1142,  1.1787]],\n",
      "\n",
      "         [[ 1.5197,  1.4145,  1.3544,  ...,  1.3694,  1.3845,  1.4896],\n",
      "          [ 1.6399,  1.5648,  1.5347,  ...,  1.5347,  1.5347,  1.6098],\n",
      "          [ 1.5798,  1.5347,  1.5347,  ...,  1.5648,  1.5347,  1.5798],\n",
      "          ...,\n",
      "          [ 1.0088,  0.9187,  0.9638,  ...,  1.1290,  1.0990,  1.0840],\n",
      "          [ 0.9337,  0.8285,  0.7684,  ...,  0.9788,  1.0990,  1.0239],\n",
      "          [ 0.9187,  0.8586,  0.7083,  ...,  0.9638,  0.9938,  0.9788]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2333,  0.2650,  0.2650,  ..., -0.1001,  0.3603,  0.3285],\n",
      "          [ 0.0110,  0.0110, -0.0208,  ...,  0.2809,  0.2650,  0.1539],\n",
      "          [-0.2430, -0.0843, -0.0525,  ...,  0.3920,  0.4873,  0.3127],\n",
      "          ...,\n",
      "          [ 0.3762,  0.3920,  0.5667,  ...,  0.0586,  0.2174, -0.1954],\n",
      "          [ 0.3762,  0.5032,  0.6461,  ...,  0.1380,  0.0110, -0.2271],\n",
      "          [ 0.5032,  0.8525,  0.8366,  ...,  0.1539, -0.0525, -0.1954]],\n",
      "\n",
      "         [[ 0.8237,  0.8721,  0.8882,  ...,  0.3879,  0.9044,  0.9851],\n",
      "          [ 0.5977,  0.6139,  0.6139,  ...,  0.8398,  0.8560,  0.7268],\n",
      "          [ 0.3234,  0.5332,  0.5977,  ...,  0.9366,  1.0496,  0.8721],\n",
      "          ...,\n",
      "          [ 0.6300,  0.5655,  0.3879,  ...,  0.7591,  0.9528,  0.5655],\n",
      "          [ 0.5493,  0.5655,  0.3234,  ...,  0.7914,  0.7107,  0.5171],\n",
      "          [ 0.6462,  0.7268,  0.5816,  ...,  0.8237,  0.6946,  0.5816]],\n",
      "\n",
      "         [[-0.1932, -0.2533, -0.2683,  ..., -0.3284, -0.0279, -0.2082],\n",
      "          [-0.3735, -0.4035, -0.3885,  ...,  0.0172, -0.1030, -0.4636],\n",
      "          [-0.5388, -0.3735, -0.3134,  ..., -0.0730,  0.0172, -0.2984],\n",
      "          ...,\n",
      "          [ 0.1674,  0.1824,  0.3627,  ..., -0.1932, -0.1181, -0.5538],\n",
      "          [ 0.1374,  0.2576,  0.4078,  ..., -0.1331, -0.2833, -0.5237],\n",
      "          [ 0.2576,  0.5881,  0.5430,  ..., -0.0880, -0.2683, -0.4336]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8683,  0.8366,  0.8525,  ...,  0.8366,  0.8366,  0.8366],\n",
      "          [ 0.8842,  0.8366,  0.8525,  ...,  0.8366,  0.8366,  0.8366],\n",
      "          [ 0.9160,  0.9001,  0.9160,  ...,  0.8842,  0.8842,  0.8842],\n",
      "          ...,\n",
      "          [ 0.0428, -0.0208, -0.0049,  ..., -0.7828, -0.6876, -0.6717],\n",
      "          [ 0.0269,  0.0904,  0.0904,  ..., -0.0049, -0.0525, -0.0843],\n",
      "          [ 0.0269, -0.0049,  0.0110,  ..., -0.1001, -0.1636, -0.1954]],\n",
      "\n",
      "         [[ 1.5822,  1.5499,  1.5660,  ...,  1.5499,  1.5338,  1.5338],\n",
      "          [ 1.5499,  1.5015,  1.5176,  ...,  1.5015,  1.4853,  1.4853],\n",
      "          [ 1.5660,  1.5176,  1.5338,  ...,  1.5176,  1.5015,  1.5015],\n",
      "          ...,\n",
      "          [ 0.2750,  0.1943,  0.2266,  ..., -0.5965, -0.4190, -0.4028],\n",
      "          [ 0.1943,  0.2427,  0.2588,  ...,  0.2266,  0.2427,  0.2266],\n",
      "          [ 0.1620,  0.1297,  0.1459,  ...,  0.1297,  0.1136,  0.0975]],\n",
      "\n",
      "         [[ 2.0606,  2.0155,  2.0305,  ...,  2.0155,  2.0456,  2.0456],\n",
      "          [ 1.9855,  1.9404,  1.9404,  ...,  1.9404,  1.9704,  1.9704],\n",
      "          [ 1.9704,  1.9254,  1.9404,  ...,  1.9404,  1.9554,  1.9554],\n",
      "          ...,\n",
      "          [-0.2683, -0.3134, -0.3134,  ..., -0.7641, -0.6740, -0.6590],\n",
      "          [-0.2683, -0.2232, -0.2082,  ..., -0.3585, -0.3585, -0.3885],\n",
      "          [-0.2533, -0.2833, -0.2683,  ..., -0.4186, -0.4186, -0.4486]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4653, -0.4812, -0.4812,  ..., -0.4971, -0.4971, -0.4971],\n",
      "          [-0.4653, -0.4812, -0.4653,  ..., -0.4812, -0.4812, -0.4812],\n",
      "          [-0.4494, -0.4653, -0.4653,  ..., -0.4653, -0.4653, -0.4653],\n",
      "          ...,\n",
      "          [-0.4812, -0.4812, -0.4812,  ..., -0.4177, -0.4177, -0.4494],\n",
      "          [-0.3542, -0.3700, -0.3383,  ..., -0.1636, -0.1636, -0.2271],\n",
      "          [-0.2113, -0.2271, -0.1954,  ..., -0.0525, -0.0843, -0.1160]],\n",
      "\n",
      "         [[ 0.2588,  0.2427,  0.2427,  ...,  0.2266,  0.2266,  0.2266],\n",
      "          [ 0.2588,  0.2427,  0.2588,  ...,  0.2427,  0.2427,  0.2427],\n",
      "          [ 0.2750,  0.2588,  0.2588,  ...,  0.2588,  0.2588,  0.2588],\n",
      "          ...,\n",
      "          [ 0.2750,  0.2588,  0.2588,  ...,  0.2750,  0.2750,  0.2911],\n",
      "          [ 0.2750,  0.2588,  0.2588,  ...,  0.3557,  0.4041,  0.3718],\n",
      "          [ 0.3073,  0.2911,  0.2911,  ...,  0.3879,  0.3718,  0.3879]],\n",
      "\n",
      "         [[ 1.2042,  1.1741,  1.1891,  ...,  1.1741,  1.1741,  1.1741],\n",
      "          [ 1.2192,  1.1891,  1.2042,  ...,  1.1891,  1.1891,  1.1891],\n",
      "          [ 1.2342,  1.2042,  1.2042,  ...,  1.2042,  1.2042,  1.2042],\n",
      "          ...,\n",
      "          [ 1.1891,  1.1441,  1.2042,  ...,  1.1140,  1.0840,  1.1140],\n",
      "          [ 1.0389,  0.9788,  1.0689,  ...,  1.0239,  1.0088,  1.0088],\n",
      "          [ 0.9337,  0.8736,  0.9638,  ...,  1.0088,  0.9337,  0.9788]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9954,  0.7413,  0.6778,  ...,  0.9636,  0.8207,  0.9795],\n",
      "          [ 0.8525,  0.6302,  0.5826,  ...,  1.0430,  1.0112,  1.0906],\n",
      "          [ 0.7096,  0.5032,  0.5984,  ...,  1.1383,  1.0430,  1.0747],\n",
      "          ...,\n",
      "          [ 1.1065,  0.6620,  0.5826,  ...,  1.4875,  1.4558,  1.5034],\n",
      "          [ 1.6304,  1.4399,  1.5034,  ...,  1.7257,  1.7257,  1.8051],\n",
      "          [ 1.7733,  1.7416,  1.8051,  ...,  1.9480,  1.9162,  1.9321]],\n",
      "\n",
      "         [[ 0.6300,  0.7107,  0.4686,  ...,  1.0335,  0.9044,  0.9528],\n",
      "          [ 0.4525,  0.5655,  0.3557,  ...,  0.9851,  0.9689,  0.9366],\n",
      "          [ 0.5009,  0.6623,  0.5977,  ...,  1.1142,  1.0173,  0.9366],\n",
      "          ...,\n",
      "          [ 0.6946,  0.7268,  0.5332,  ...,  1.5499,  1.5338,  1.4692],\n",
      "          [ 1.3401,  1.5499,  1.4692,  ...,  1.8081,  1.8242,  1.8081],\n",
      "          [ 1.6467,  1.8727,  1.7597,  ...,  2.0179,  2.0018,  1.9372]],\n",
      "\n",
      "         [[ 0.3928,  0.6783,  0.5581,  ...,  0.9938,  0.8736,  0.8886],\n",
      "          [ 0.4228,  0.7384,  0.6482,  ...,  1.1591,  1.1441,  1.0840],\n",
      "          [ 0.2876,  0.6332,  0.6632,  ...,  1.1441,  1.0689,  0.9638],\n",
      "          ...,\n",
      "          [ 0.6632,  0.8586,  0.7534,  ...,  1.5497,  1.5347,  1.4446],\n",
      "          [ 1.1140,  1.5197,  1.5197,  ...,  1.7901,  1.8052,  1.7601],\n",
      "          [ 1.4145,  1.8502,  1.8502,  ...,  2.0756,  2.0606,  1.9704]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1063,  0.3285,  0.5032,  ...,  1.9162,  1.8368,  1.8686],\n",
      "          [-0.0049,  0.2492,  0.4873,  ...,  1.9797,  1.9162,  1.9638],\n",
      "          [-0.1160,  0.0745,  0.3127,  ...,  1.9321,  1.8845,  1.9638],\n",
      "          ...,\n",
      "          [-0.1636, -0.2430, -0.2748,  ..., -0.0525, -0.1478, -0.2748],\n",
      "          [-0.1636, -0.2113, -0.1636,  ..., -0.1478, -0.2748, -0.4018],\n",
      "          [-0.3065, -0.2589, -0.2748,  ..., -0.3383, -0.4177, -0.5447]],\n",
      "\n",
      "         [[ 0.1459,  0.3718,  0.5493,  ...,  1.9856,  1.9049,  1.9372],\n",
      "          [ 0.0329,  0.2911,  0.5332,  ...,  2.0502,  1.9856,  2.0340],\n",
      "          [-0.0801,  0.1136,  0.3557,  ...,  2.0018,  1.9533,  2.0340],\n",
      "          ...,\n",
      "          [-0.1285, -0.2092, -0.2414,  ..., -0.0155, -0.1123, -0.2414],\n",
      "          [-0.1285, -0.1769, -0.1285,  ..., -0.1123, -0.2414, -0.3705],\n",
      "          [-0.2737, -0.2253, -0.2414,  ..., -0.3060, -0.3867, -0.5158]],\n",
      "\n",
      "         [[ 0.2726,  0.4829,  0.6482,  ...,  1.9855,  1.9103,  1.9404],\n",
      "          [ 0.1674,  0.4078,  0.6332,  ...,  2.0456,  1.9855,  2.0305],\n",
      "          [ 0.0622,  0.2425,  0.4679,  ...,  2.0005,  1.9554,  2.0305],\n",
      "          ...,\n",
      "          [ 0.0172, -0.0580, -0.0880,  ...,  0.1223,  0.0322, -0.0880],\n",
      "          [ 0.0172, -0.0279,  0.0172,  ...,  0.0322, -0.0880, -0.2082],\n",
      "          [-0.1181, -0.0730, -0.0880,  ..., -0.1481, -0.2232, -0.3434]]]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "3072\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def generate_cifar10_dataloader_with_Q_A_label(full_train_loader: DataLoader, \n",
    "                                                  question_type: QuestionType,\n",
    "                                                  question_size: int,\n",
    "                                                  batch_size: int) ->[DataLoader, int, int]:\n",
    "    \n",
    "    for i, (datas, labels) in enumerate(full_train_loader):\n",
    "        all_class_size = torch.max(labels) + 1 # K is number of classes, full_train_loader is full batch\n",
    "        \n",
    "    Q_A_labels_tensor = generate_Q_A_labels(labels, question_type, all_class_size, question_size)\n",
    "    Q_A_labels_matrix_dataset = torch.utils.data.TensorDataset(datas, Q_A_labels_tensor.float())\n",
    "    Q_A_labels_matrix_train_loader = torch.utils.data.DataLoader(dataset=Q_A_labels_matrix_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dimension = int(datas.reshape(-1).shape[0]/datas.shape[0])\n",
    "    return Q_A_labels_matrix_train_loader, dimension, all_class_size.tolist()\n",
    "\n",
    "Q_A_labels_matrix_train_loader, dimension, all_class_size = generate_cifar10_dataloader_with_Q_A_label(full_train_loader, \n",
    "                                                                                                           QuestionType.WHICH_ONE,\n",
    "                                                                                                           question_size=9,\n",
    "                                                                                                           batch_size=64)\n",
    "Q_A_datas, Q_A_labels = next(iter(Q_A_labels_matrix_train_loader))\n",
    "print(Q_A_datas)\n",
    "print(Q_A_labels)\n",
    "print(dimension)\n",
    "print(all_class_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQyJl_0N-WWG",
    "outputId": "df832967-0186-4a49-86a6-ae282f2195fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x229028c0340>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2294f0ceee0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2294f0cee50>,\n",
       " 3072,\n",
       " 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from traitlets.traitlets import Integer\n",
    "# Unclear!!!\n",
    "DataSet_2_DataLoader_generator = {\n",
    "    #DataSet.MNIST: generate_mnist_dataloader,\n",
    "    DataSet.CIFAR10: generate_cifar10_dataloader,\n",
    "    #DataSet.CIFAR100: generate_cifar100_dataloader,\n",
    "}\n",
    "DataSet_2_DataLoader_generator_with_Q_A_label = {\n",
    "    #DataSet.MNIST: generate_mnist_dataloader,\n",
    "    DataSet.CIFAR10: generate_cifar10_dataloader_with_Q_A_label,\n",
    "    #DataSet.CIFAR100: generate_cifar100_dataloader,\n",
    "}\n",
    "\n",
    "def DataSet_2_DataLoader_with_Q_A_label(dataset: DataSet,\n",
    "                                             question_type: QuestionType,\n",
    "                                             question_size: int,\n",
    "                                             batch_size: int\n",
    "                                             ) -> [DataLoader, DataLoader, DataLoader, int, int]:\n",
    "    \n",
    "    dataloader_generator = DataSet_2_DataLoader_generator[dataset]\n",
    "    full_train_loader, train_loader, test_loader = dataloader_generator(batch_size)\n",
    "    dataloader_generator_with_Q_A_label = DataSet_2_DataLoader_generator_with_Q_A_label[dataset]\n",
    "    Q_A_labels_matrix_train_loader, dimension, all_class_size = dataloader_generator_with_Q_A_label(full_train_loader, question_type, question_size, batch_size)\n",
    "    \n",
    "    return Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size\n",
    "\n",
    "DataSet_2_DataLoader_with_Q_A_label(DataSet.CIFAR10, QuestionType.WHICH_ONE, 9, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uttS2WgHgpB"
   },
   "source": [
    "# Model excution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "izJeh7tu-WWG"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def mae_loss(outputs, labels):\n",
    "    sm_outputs = F.softmax(outputs, dim=1)\n",
    "    loss_fn = nn.L1Loss(reduction='none')\n",
    "    loss_matrix = loss_fn(sm_outputs, labels.float())\n",
    "    sample_loss = loss_matrix.sum(dim=-1)\n",
    "    return sample_loss\n",
    "    \n",
    "def mse_loss(outputs, labels):\n",
    "    sm_outputs = F.softmax(outputs, dim=1)\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    loss_matrix = loss_fn(sm_outputs, labels.float())\n",
    "    sample_loss = loss_matrix.sum(dim=-1)\n",
    "    return sample_loss\n",
    "\n",
    "def gce_loss(outputs, labels):\n",
    "    q = 0.7\n",
    "    sm_outputs = F.softmax(outputs, dim=1)\n",
    "    pow_outputs = torch.pow(sm_outputs, q)\n",
    "    sample_loss = (1-(pow_outputs*labels).sum(dim=1))/q # n\n",
    "    return sample_loss\n",
    "\n",
    "def phuber_ce_loss(outputs, labels):\n",
    "    trunc_point = 0.1\n",
    "    n = labels.shape[0]\n",
    "    soft_max = nn.Softmax(dim=1)\n",
    "    sm_outputs = soft_max(outputs)\n",
    "    final_outputs = sm_outputs * labels\n",
    "    final_confidence = final_outputs.sum(dim=1)\n",
    "    ce_index = (final_confidence > trunc_point)\n",
    "    sample_loss = torch.zeros(n).to(device)\n",
    "\n",
    "    if ce_index.sum() > 0:\n",
    "        ce_outputs = outputs[ce_index,:]\n",
    "        logsm = nn.LogSoftmax(dim=-1)\n",
    "        logsm_outputs = logsm(ce_outputs)\n",
    "        final_ce_outputs = logsm_outputs * labels[ce_index,:]\n",
    "        sample_loss[ce_index] = - final_ce_outputs.sum(dim=-1)\n",
    "\n",
    "    linear_index = (final_confidence <= trunc_point)\n",
    "\n",
    "    if linear_index.sum() > 0:\n",
    "        sample_loss[linear_index] = -math.log(trunc_point) + (-1/trunc_point)*final_confidence[linear_index] + 1\n",
    "\n",
    "    return sample_loss\n",
    "\n",
    "def ce_loss(outputs, labels):\n",
    "    logsm = nn.LogSoftmax(dim=1)\n",
    "    logsm_outputs = logsm(outputs)\n",
    "    final_outputs = logsm_outputs * labels\n",
    "    sample_loss = - final_outputs.sum(dim=1)\n",
    "    return sample_loss\n",
    "\n",
    "def W_O_loss(loss_fn, outputs, labels, device, question_class_size, all_class_size):\n",
    "    n, k = labels.shape[0], labels.shape[1]\n",
    "    temp_loss = torch.zeros(n, k).to(device)\n",
    "    for i in range(k):\n",
    "        tempY = torch.zeros(n, k).to(device)\n",
    "        tempY[:, i] = 1.0\n",
    "        temp_loss[:, i] = loss_fn(outputs, tempY)\n",
    "        \n",
    "    candidate_loss = (temp_loss * labels).sum(dim=1)\n",
    "    noncandidate_loss = (temp_loss * (1-labels)).sum(dim=1)\n",
    "    total_loss = candidate_loss - ((all_class_size - question_class_size) * (all_class_size - question_class_size - 1))/(question_class_size * (2*all_class_size - question_class_size - 1.0)) * noncandidate_loss\n",
    "    average_loss = total_loss.mean()\n",
    "    return average_loss\n",
    "\n",
    "def I_I_loss(loss_fn, outputs, labels, device, question_class_size, all_class_size):\n",
    "    n, k = labels.shape[0], labels.shape[1]\n",
    "    temp_loss = torch.zeros(n, k).to(device)\n",
    "    for i in range(k):\n",
    "        tempY = torch.zeros(n, k).to(device)\n",
    "        tempY[:, i] = 1.0\n",
    "        temp_loss[:, i] = ce_loss(outputs, tempY)\n",
    "        \n",
    "    candidate_loss = (temp_loss * labels).sum(dim=1)\n",
    "    noncandidate_loss = (temp_loss * (1-labels)).sum(dim=1)\n",
    "    total_loss = candidate_loss - (2*question_class_size**2 + all_class_size**2 - all_class_size*(2*question_class_size + 1))/(2*question_class_size * (all_class_size - question_class_size)) * noncandidate_loss\n",
    "    average_loss = total_loss.mean()\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7eQ0uYqy-WWH"
   },
   "outputs": [],
   "source": [
    "class mlp_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(mlp_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, self.num_flat_features(x))\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HiI0NlQ1-WWH"
   },
   "outputs": [],
   "source": [
    "def accuracy_check(loader, model, device):\n",
    "    with torch.no_grad():\n",
    "        total, num_samples = 0, 0\n",
    "        for images, labels in loader:\n",
    "            labels, images = labels.to(device), images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += (predicted == labels).sum().item()\n",
    "            num_samples += labels.size(0) \n",
    "    return total / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "naI292b5-WWH"
   },
   "outputs": [],
   "source": [
    "def show_score(epoch,max_epoch, itr, max_itr, loss, acc, is_val=False):\n",
    "    if is_val:\n",
    "        print('\\r{} EPOCH[{:03}/{:03}] ITR [{:04}/{:04}] ACC:{:03f}'.format(\"TEST  \" if is_val else \"TRAIN\", epoch, max_epoch, itr, max_itr, acc*100),end = '')\n",
    "    else:\n",
    "        print('\\r{} EPOCH[{:03}/{:03}] ITR [{:04}/{:04}] LOSS:{:.05f} ACC:{:03f}'.format(\"VAL  \" if is_val else \"TRAIN\", epoch, max_epoch, itr, max_itr, loss, acc*100), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Qr7jT0aV-WWI"
   },
   "outputs": [],
   "source": [
    "def Train_Eval(model, \n",
    "               question_type, \n",
    "               question_class_size, \n",
    "               all_class_size, \n",
    "               criterion, \n",
    "               optimizer, \n",
    "               data_loader, \n",
    "               evaluation_data_loader_train, \n",
    "               evaluation_data_loader_test, \n",
    "               device, \n",
    "               epoch, \n",
    "               max_epoch):\n",
    "        \n",
    "    total_loss_train = 0.0\n",
    "    total_acc_train = 0.0\n",
    "    total_acc_test = 0.0\n",
    "    counter = 0\n",
    "\n",
    "    for n, (data, label) in enumerate(data_loader):\n",
    "        model.train()\n",
    "        counter += data.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(data)\n",
    "        if question_type == QuestionType.WHICH_ONE:\n",
    "            loss = W_O_loss(criterion, output, label.float(), device, question_class_size, all_class_size)\n",
    "        elif question_type == QuestionType.IS_IN:\n",
    "            loss = I_I_loss(criterion, output, label.float(), device, question_class_size, all_class_size)\n",
    "        else:\n",
    "            loss = criterion(output,label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        total_acc_train += accuracy_check(evaluation_data_loader_train, model, device)\n",
    "        total_acc_test += accuracy_check(evaluation_data_loader_test, model, device)\n",
    "\n",
    "\n",
    "        show_score(epoch+1, max_epoch, n+1, len(data_loader), total_loss_train/(n+1), total_acc_train/counter, is_val=False)\n",
    "        print()\n",
    "        show_score(epoch+1, max_epoch, n+1, len(data_loader), '', total_acc_test/counter, is_val=True)\n",
    "        print()\n",
    "\n",
    "    return total_loss , total_acc_train, total_acc_test \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U3UMkIUz-WWI"
   },
   "outputs": [],
   "source": [
    "def Q_A_label_Train_Eval(dataset, \n",
    "                          question_type, \n",
    "                          question_class_size, \n",
    "                          model, \n",
    "                          batch_size, \n",
    "                          loss_fn, \n",
    "                          EPOCHS):\n",
    "    Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size = DataSet_2_DataLoader_with_Q_A_label(dataset, \n",
    "                                                                                                                           question_type, \n",
    "                                                                                                                           question_class_size,\n",
    "                                                                                                                           batch_size)\n",
    "    DEVICE= torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = model(input_dim=dimension, hidden_dim=500, output_dim=all_class_size).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    train_loss_list = []\n",
    "\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    #criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, test_acc = Train_Eval(model=model, \n",
    "                                                    question_type=question_type,\n",
    "                                                    question_class_size=question_class_size,\n",
    "                                                    all_class_size=all_class_size,\n",
    "                                                    criterion=loss_fn,\n",
    "                                                    optimizer=optimizer, \n",
    "                                                    data_loader=Q_A_labels_matrix_train_loader,\n",
    "                                                    evaluation_data_loader_train=train_loader,\n",
    "                                                    evaluation_data_loader_test=test_loader,\n",
    "                                                    device=DEVICE, \n",
    "                                                    epoch=epoch, \n",
    "                                                    max_epoch=EPOCHS)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(f'TRAIN EPOCH[{epoch+1}/{EPOCHS}] LOSS: {train_loss_list.mean()} ACC:{train_acc_list.mean()}')\n",
    "        print(f'TEST EPOCH[{epoch+1}/{EPOCHS}] ACC:{test_acc_list.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "i5I4hQib-WWI",
    "outputId": "6dc1435a-248a-4f8e-92bc-121f7695d939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "TRAIN EPOCH[001/300] ITR [0001/1563] LOSS:2.28674 ACC:0.601562\n",
      "TEST   EPOCH[001/300] ITR [0001/1563] ACC:0.598750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-01eb8d77ac7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m Q_A_label_Train_Eval(dataset=DataSet.CIFAR10, \n\u001b[0m\u001b[0;32m      2\u001b[0m                       \u001b[0mquestion_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQuestionType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHICH_ONE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                       \u001b[0mquestion_class_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                       \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-ecad65f9c567>\u001b[0m in \u001b[0;36mQ_A_label_Train_Eval\u001b[1;34m(dataset, question_type, question_class_size, model, batch_size, loss_fn, EPOCHS)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         train_loss, train_acc, test_acc = Train_Eval(model=model, \n\u001b[0m\u001b[0;32m     24\u001b[0m                                                     \u001b[0mquestion_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                                     \u001b[0mquestion_class_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_class_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-852f6455ca01>\u001b[0m in \u001b[0;36mTrain_Eval\u001b[1;34m(model, question_type, question_class_size, all_class_size, criterion, optimizer, data_loader, evaluation_data_loader_train, evaluation_data_loader_test, device, epoch, max_epoch)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mtotal_acc_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluation_data_loader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mtotal_acc_test\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluation_data_loader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fdf7d9ef1b66>\u001b[0m in \u001b[0;36maccuracy_check\u001b[1;34m(loader, model, device)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q_A_label_Train_Eval(dataset=DataSet.CIFAR10, \n",
    "                      question_type=QuestionType.WHICH_ONE, \n",
    "                      question_class_size=9, \n",
    "                      model=mlp_model, \n",
    "                      batch_size=32, \n",
    "                      loss_fn=ce_loss, \n",
    "                      EPOCHS=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "klKwXNTl-WWI"
   },
   "outputs": [],
   "source": [
    "def Ord_label_Train_Eval(dataset, \n",
    "                          model, \n",
    "                          batch_size, \n",
    "                          loss_fn, \n",
    "                          EPOCHS):\n",
    "    Q_A_labels_matrix_train_loader, train_loader, test_loader, dimension, all_class_size = DataSet_2_DataLoader_with_Q_A_label(dataset, \n",
    "                                                                                                                                   QuestionType.WHICH_ONE, \n",
    "                                                                                                                                   5,\n",
    "                                                                                                                                   batch_size)\n",
    "    DEVICE= torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = model(input_dim=dimension, hidden_dim=500, output_dim=all_class_size).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    train_loss_list = []\n",
    "\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    #criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss,train_acc = Train_Eval(model=model, \n",
    "                                          question_type=None,\n",
    "                                          question_class_size=None,\n",
    "                                          all_class_size=None,\n",
    "                                          criterion=loss_fn,\n",
    "                                          optimizer=optimizer, \n",
    "                                          data_loader=train_loader,\n",
    "                                          evaluation_data_loader_train=train_loader,\n",
    "                                          evaluation_data_loader_test=test_loader,\n",
    "                                          device=DEVICE, \n",
    "                                          epoch=epoch, \n",
    "                                          max_epoch=EPOCHS)\n",
    "        \n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(f'TRAIN EPOCH[{epoch+1}/{EPOCHS}] LOSS: {train_loss_list.mean()} ACC:{train_acc_list.mean()}')\n",
    "        print(f'TEST EPOCH[{epoch+1}/{EPOCHS}] ACC:{test_acc_list.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "6WUN_qgA-WWJ",
    "outputId": "25085349-1b02-4194-fc5c-db96a3e74c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "TRAIN EPOCH[001/300] ITR [0001/0782] LOSS:2.32732 ACC:0.312250\n",
      "TEST   EPOCH[001/300] ITR [0001/0782] ACC:0.317812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-63509f12d064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Ord_label_Train_Eval(dataset=DataSet.CIFAR10, \n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       EPOCHS=300)\n",
      "\u001b[0;32m<ipython-input-56-87ee05022a96>\u001b[0m in \u001b[0;36mOrd_label_Train_Eval\u001b[0;34m(dataset, model, batch_size, loss_fn, EPOCHS)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         train_loss,train_acc = Train_Eval(model=model, \n\u001b[0m\u001b[1;32m     22\u001b[0m                                           \u001b[0mquestion_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                           \u001b[0mquestion_class_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-852f6455ca01>\u001b[0m in \u001b[0;36mTrain_Eval\u001b[0;34m(model, question_type, question_class_size, all_class_size, criterion, optimizer, data_loader, evaluation_data_loader_train, evaluation_data_loader_test, device, epoch, max_epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtotal_acc_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-fdf7d9ef1b66>\u001b[0m in \u001b[0;36maccuracy_check\u001b[0;34m(loader, model, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \"\"\"\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ord_label_Train_Eval(dataset=DataSet.CIFAR10, \n",
    "                      model=mlp_model, \n",
    "                      batch_size=64, \n",
    "                      loss_fn=nn.CrossEntropyLoss(), \n",
    "                      EPOCHS=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k02cVpT4-WWJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
